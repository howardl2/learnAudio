{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import neighbors, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "\n",
    "from matplotlib.pyplot import specgram\n",
    "import matplotlib.style as ms\n",
    "ms.use(\"seaborn-muted\")\n",
    "%matplotlib inline\n",
    "\n",
    "import IPython.display\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "# import tensorflow as tf\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files(filepaths):\n",
    "    raw_sounds = []\n",
    "    for filepath in filepaths:\n",
    "        X,sr = librosa.load(filepath)\n",
    "        raw_sounds.append(X)\n",
    "    return raw_sounds\n",
    "\n",
    "def extract_feature(file_name):\n",
    "    print(\"extract_feature\")\n",
    "    X, sample_rate = librosa.load(file_name)\n",
    "    print(\"loaded\")\n",
    "    stft = np.abs(librosa.stft(X))\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X),\n",
    "    sr=sample_rate).T,axis=0)\n",
    "    print(\"returning\")\n",
    "    return mfccs,chroma,mel,contrast,tonnetz\n",
    "\n",
    "def parse_audio_files(parent_dir,sub_dirs,file_ext=\"*.wav\"):\n",
    "    features, labels = np.empty((0,193)), np.empty(0) #the shape 193 comes from the shape of features combined\n",
    "    for label, sub_dir in enumerate(sub_dirs):\n",
    "        print(label, sub_dir)\n",
    "        for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
    "            try:\n",
    "                print(fn)\n",
    "                mfccs, chroma, mel, contrast, tonnetz = extract_feature(fn)\n",
    "            except Exception as e:\n",
    "                print(\"Error encountered while parsing file: \", fn)\n",
    "                continue\n",
    "            ext_features = np.hstack([mfccs,chroma,mel,contrast,tonnetz])\n",
    "\n",
    "            features = np.vstack([features,ext_features])\n",
    "            labels = np.append(labels, fn.split('\\\\')[2].split('-')[1])\n",
    "    return np.array(features), np.array(labels, dtype = np.int)\n",
    "\n",
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels,n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels),labels] = 1\n",
    "    return one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting Audio parsing\")\n",
    "parent_dir = 'TalkingData'\n",
    "dirs = [\"set1\", \"set2\", \"fold1\", \"fold2\", \"fold3\"]\n",
    "path = \"TalkingData\\set1\\talking_111841-3-0-0.wav\"\n",
    "# X, sample_rate = librosa.load(path)\n",
    "features, labels = parse_audio_files(parent_dir, dirs)\n",
    "\n",
    "print(\"Done parsing audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./pickles/features.pckl', 'wb')\n",
    "pickle.dump(features,f)\n",
    "f.close()\n",
    "fl = open('pickles/labels.pckl', 'wb')\n",
    "pickle.dump(labels,fl)\n",
    "fl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"./pickles/features.pckl\", 'rb')\n",
    "features = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "\n",
    "fl = open(\"./pickles/labels.pckl\", \"rb\")\n",
    "labels = pickle.load(fl)\n",
    "fl.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "ending\n"
     ]
    }
   ],
   "source": [
    "print(\"starting\")\n",
    "\n",
    "# print(labels.shape)\n",
    "\n",
    "\n",
    "labels = one_hot_encode(labels)\n",
    "\n",
    "train_test_split = np.random.rand(len(features)) < 0.70\n",
    "train_x = features[train_test_split]\n",
    "train_y = labels[train_test_split]\n",
    "test_x = features[~train_test_split]\n",
    "test_y = labels[~train_test_split]\n",
    "\n",
    "print(\"ending\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "# setup data/model\n",
    "n_neighbors = 15\n",
    "\n",
    "# iris = datasets.load_iris()\n",
    "\n",
    "# X = iris.data[:, :2]\n",
    "X = train_x\n",
    "y = train_y\n",
    "# y = iris.target\n",
    "\n",
    "h = 0.02\n",
    "\n",
    "# Create color maps\n",
    "# cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "# cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "\n",
    "for weights in ['uniform', 'distance']:\n",
    "    # we create an instance of Neighbours Classifier and fit the data.\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "#     x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "#     y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "#     xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "#                          np.arange(y_min, y_max, h))\n",
    "#     print(xx.shape, yy.shape)\n",
    "#     Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    \n",
    "    pred_y = clf.predict(test_x)\n",
    "    result = test_y==pred_y.all()\n",
    "    print(sum(sum(result==True)) / (result.shape[1] * result.shape[0]))\n",
    "    # Put the result into a color plot\n",
    "#     Z = Z.reshape(xx.shape)\n",
    "#     plt.figure()\n",
    "# #     plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "#     # Plot also the training points\n",
    "#     plt.scatter(X[:, 0], X[:, 1], c=y,\n",
    "#                 edgecolor='k', s=20)\n",
    "#     plt.xlim(xx.min(), xx.max())\n",
    "#     plt.ylim(yy.min(), yy.max())\n",
    "#     plt.title(\"3-Class classification (k = %i, weights = '%s')\"\n",
    "#               % (n_neighbors, weights))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
