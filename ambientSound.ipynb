{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import specgram\n",
    "import matplotlib.style as ms\n",
    "ms.use(\"seaborn-muted\")\n",
    "%matplotlib inline\n",
    "\n",
    "import IPython.display\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pickle\n",
    "\n",
    "NUMBER_OF_CLASSES = 2\n",
    "NUMBER_OF_ITERATIONS = 5000\n",
    "export_path_base = 'C:\\\\Users\\\\Howard\\\\Documents\\\\learnAudio\\\\ambientSoundModels'\n",
    "\n",
    "\n",
    "# tf.app.flags.DEFINE_integer('training_iteration', NUMBER_OF_ITERATIONS, 'number of training iterations.')\n",
    "# tf.app.flags.DEFINE_integer('model_version', 1, 'version number of the model.')\n",
    "# tf.app.flags.DEFINE_string('work_dir', '/tmp', 'Working directory.')\n",
    "# FLAGS = tf.app.flags.FLAGS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_files(filepaths):\n",
    "    raw_sounds = []\n",
    "    for filepath in filepaths:\n",
    "        X,sr = librosa.load(filepath)\n",
    "        raw_sounds.append(X)\n",
    "    return raw_sounds\n",
    "\n",
    "\n",
    "def plot_waves(sound_names,raw_sounds):\n",
    "    i = 1\n",
    "    fig = plt.figure(figsize=(25,60), dpi = 900)\n",
    "    for n,f in zip(sound_names,raw_sounds):\n",
    "        print(n,f)\n",
    "        plt.subplot(10,1,i)\n",
    "        librosa.display.waveplot(np.array(f),sr=22050)\n",
    "        plt.title(n.title())\n",
    "        i += 1\n",
    "    plt.suptitle(\"Figure 1: Waveplot\",x=0.5, y=0.915,fontsize=18)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sound_file_paths = [\"Sound-Data/fold1/15564-2-0-0.wav\", \"Sound-Data/fold1/21684-9-0-5.wav\"]\n",
    "\n",
    "#sound_names = [\"children playing\", \"street music\"]\n",
    "\n",
    "#raw_sounds = load_files(sound_file_paths)\n",
    "\n",
    "# plot_waves(sound_names,raw_sounds)\n",
    "\n",
    "\n",
    "\n",
    "# X, sr = librosa.load(\"Sound-Data/fold1/7383-3-0-0.wav\")\n",
    "# librosa.display.waveplot(np.array(X), sr=22050)\n",
    "# plt.title(\"dog bark\".title())\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_feature(file_name):\n",
    "    X, sample_rate = librosa.load(file_name)\n",
    "    stft = np.abs(librosa.stft(X))\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X),\n",
    "    sr=sample_rate).T,axis=0)\n",
    "    return mfccs,chroma,mel,contrast,tonnetz\n",
    "\n",
    "def parse_audio_files(parent_dir,sub_dirs,file_ext=\"*.wav\"):\n",
    "    features, labels = np.empty((0,193)), np.empty(0) #the shape 193 comes from the shape of features combined\n",
    "    for label, sub_dir in enumerate(sub_dirs):\n",
    "        print(label, sub_dir)\n",
    "        for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
    "            try:\n",
    "                mfccs, chroma, mel, contrast,tonnetz = extract_feature(fn)\n",
    "            except Exception as e:\n",
    "                print(\"Error encountered while parsing file: \", fn)\n",
    "                continue\n",
    "            ext_features = np.hstack([mfccs,chroma,mel,contrast,tonnetz])\n",
    "\n",
    "            features = np.vstack([features,ext_features])\n",
    "            labels = np.append(labels, fn.split('\\\\')[2].split('-')[1])\n",
    "    return np.array(features), np.array(labels, dtype = np.int)\n",
    "\n",
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels,n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels),labels] = 1\n",
    "    return one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Audio parsing\n",
      "0 Ambient_1_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Howard\\Anaconda3\\lib\\site-packages\\resampy\\core.py:90: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if not np.issubdtype(x.dtype, np.float):\n",
      "C:\\Users\\Howard\\Anaconda3\\lib\\site-packages\\librosa\\util\\utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n",
      "C:\\Users\\Howard\\Anaconda3\\lib\\site-packages\\librosa\\util\\utils.py:1640: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if not np.issubdtype(dtype, float):\n",
      "C:\\Users\\Howard\\Anaconda3\\lib\\site-packages\\librosa\\util\\utils.py:1725: FutureWarning: Conversion of the second argument of issubdtype from `complex` to `np.complexfloating` is deprecated. In future, it will be treated as `np.complex128 == np.dtype(complex).type`.\n",
      "  if np.issubdtype(x.dtype, float) or np.issubdtype(x.dtype, complex):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Ambient_1_4\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting Audio parsing\")\n",
    "parent_dir = 'Sound-Data/renameThese'\n",
    "# dirs = [\"fold1c\",\"fold2c\", \"fold3c\", \"fold4\",\"AmbientRecordings\"]\n",
    "dirs = [\"Ambient_1_3\", \"Ambient_1_4\", \"Ambient_1_11\", \"toilet_sounds\",\"Ambient_1_15\"]\n",
    "features, labels = parse_audio_files(parent_dir, dirs)\n",
    "\n",
    "print(\"Done parsing audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('./pickles/features.pckl', 'wb')\n",
    "pickle.dump(features,f)\n",
    "f.close()\n",
    "fl = open('pickles/labels.pckl', 'wb')\n",
    "pickle.dump(labels,fl)\n",
    "fl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"./pickles/features.pckl\", 'rb')\n",
    "features = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "\n",
    "fl = open(\"./pickles/labels.pckl\", \"rb\")\n",
    "labels = pickle.load(fl)\n",
    "fl.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "ending\n"
     ]
    }
   ],
   "source": [
    "print(\"starting\")\n",
    "\n",
    "# print(labels.shape)\n",
    "\n",
    "\n",
    "labels = one_hot_encode(labels)\n",
    "\n",
    "train_test_split = np.random.rand(len(features)) < 0.70\n",
    "train_x = features[train_test_split]\n",
    "train_y = labels[train_test_split]\n",
    "test_x = features[~train_test_split]\n",
    "test_y = labels[~train_test_split]\n",
    "\n",
    "print(\"ending\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = [i for i in range(0,NUMBER_OF_CLASSES)]\n",
    "# names = [\"air_conditioner\",\"children_playing\",\"street_music\", \"toilet\"]\n",
    "# names = [\"air_conditioner\",\"children_playing\", \"toilet\", \"ambient_sounds\"]\n",
    "names = [\"not_bathroom\", \"bathroom\"]\n",
    "\n",
    "# define parameters\n",
    "training_epochs = NUMBER_OF_ITERATIONS\n",
    "n_dim = features.shape[1]\n",
    "n_classes = NUMBER_OF_CLASSES\n",
    "n_hidden_units_one = 280 \n",
    "n_hidden_units_two = 300\n",
    "sd = 1 / np.sqrt(n_dim)\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32,[None,n_dim])\n",
    "Y = tf.placeholder(tf.float32,[None,n_classes])\n",
    "\n",
    "W_1 = tf.Variable(tf.random_normal([n_dim,n_hidden_units_one], mean = 0, stddev=sd))\n",
    "b_1 = tf.Variable(tf.random_normal([n_hidden_units_one], mean = 0, stddev=sd))\n",
    "h_1 = tf.nn.tanh(tf.matmul(X,W_1) + b_1)\n",
    "\n",
    "\n",
    "W_2 = tf.Variable(tf.random_normal([n_hidden_units_one,n_hidden_units_two], mean = 0, stddev=sd))\n",
    "b_2 = tf.Variable(tf.random_normal([n_hidden_units_two], mean = 0, stddev=sd))\n",
    "h_2 = tf.nn.sigmoid(tf.matmul(h_1,W_2) + b_2)\n",
    "\n",
    "\n",
    "W = tf.Variable(tf.random_normal([n_hidden_units_two,n_classes], mean = 0, stddev=sd))\n",
    "b = tf.Variable(tf.random_normal([n_classes], mean = 0, stddev=sd))\n",
    "y_ = tf.nn.softmax(tf.matmul(h_2,W) + b)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost_function = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(y_), reduction_indices=[1])) \n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "cost_history = np.empty(shape=[1],dtype=float)\n",
    "y_true, y_pred = None, None\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(training_epochs):            \n",
    "        _,cost = sess.run([optimizer,cost_function],feed_dict={X:train_x,Y:train_y})\n",
    "        cost_history = np.append(cost_history,cost)\n",
    "    \n",
    "    y_pred = sess.run(tf.argmax(y_,1),feed_dict={X: test_x})\n",
    "    y_true = sess.run(tf.argmax(test_y,1))\n",
    "    \n",
    "    saver.save(sess, \"./checkpoints/\"+\"NN-model.ckpt\")\n",
    "    tf.train.write_graph(sess.graph_def, './tmp/model', 'ambient_nn.pb', as_text=False)\n",
    "\n",
    "    \n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints\\NN-model.ckpt\n",
      "INFO:tensorflow:Froze 6 variables.\n",
      "Converted 6 variables to const ops.\n",
      "227 ops in the final graph.\n",
      "WARNING:tensorflow:From C:\\Users\\Howard\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.contrib.lite.python.lite' has no attribute 'toco_convert'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5b2b4b3d9119>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;31m# create tflite file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0mtflite_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoco_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_graph_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m     \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"converteds_model.tflite\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtflite_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.contrib.lite.python.lite' has no attribute 'toco_convert'"
     ]
    }
   ],
   "source": [
    "# retrieve checkpoints\n",
    "checkpoint = tf.train.get_checkpoint_state(\"./checkpoints\")\n",
    "input_checkpoint = checkpoint.model_checkpoint_path\n",
    "\n",
    "# decide on the file name for frozen model\n",
    "absolute_model_dir = \"/\".join(input_checkpoint.split(\"/\")[:-1])\n",
    "output_graph = absolute_model_dir + \"/frozen_model.pb\"\n",
    "\n",
    "clear_devices = True\n",
    "\n",
    "img = tf.placeholder(name=\"img\", dtype=tf.float32, shape=(1, 64, 64, 3))\n",
    "val = img + tf.constant([1., 2., 3.]) + tf.constant([1., 4., 4.])\n",
    "out = tf.identity(val, name=\"out\")\n",
    "\n",
    "# start a session using a temporary fresh Graph\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    # import the meta graph in the current default Graph\n",
    "    saver = tf.train.import_meta_graph(input_checkpoint + \".meta\", clear_devices=clear_devices)\n",
    "    # restore the weights\n",
    "    saver.restore(sess, input_checkpoint)\n",
    "    \n",
    "    # provide the list of node names\n",
    "    output_node_names = [n.name for n in tf.get_default_graph().as_graph_def().node]\n",
    "    \n",
    "#     final_output_node_names = tf.graph_util.remove_training_nodes(\n",
    "#         output_node_names    \n",
    "#     )\n",
    "    \n",
    "    # use a built-in TF helper to export variables to constants\n",
    "    output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "        sess, # The session is used to retrieve the weights\n",
    "        tf.get_default_graph().as_graph_def(), # The graph_def is used to retrieve the nodes \n",
    "        output_node_names # The output node names are used to select the usefull nodes\n",
    "    )\n",
    "    \n",
    "    # serialize and dump the output graph to the filesystem\n",
    "    with tf.gfile.GFile(output_graph, \"wb\") as f:\n",
    "        f.write(output_graph_def.SerializeToString())\n",
    "    print(\"%d ops in the final graph.\" % len(output_graph_def.node))\n",
    "\n",
    "    # create tflite file\n",
    "    tflite_model = tf.contrib.lite.toco_convert(output_graph_def, [img], [out])\n",
    "    open(\"converteds_model.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.plot(cost_history)\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.axis([0,training_epochs,0,np.max(cost_history)])\n",
    "plt.show()\n",
    "\n",
    "p,r,f,s = precision_recall_fscore_support(y_true, y_pred, average=\"micro\")\n",
    "print(\"F-Score:\", round(f,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## notes\n",
    "confusion matrix\n",
    "test on real data\n",
    "- record random real life events to gather more random sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = [i for i in range(0,NUMBER_OF_CLASSES)]\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_true, y_pred,labels=[i for i in range(0,NUMBER_OF_CLASSES)])\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from prettytable import PrettyTable\n",
    "count = [0.00 for i in range(0,NUMBER_OF_CLASSES)]\n",
    "for i in y_true:\n",
    "    count[i] += 1\n",
    "\n",
    "\n",
    "copy = list()\n",
    "for index1, l in enumerate(cm):\n",
    "    copy.append([])\n",
    "    for index2, item in enumerate(l):\n",
    "        copy[index1].append(item / count[index1] * 100)\n",
    "\n",
    "\n",
    "\n",
    "names = [\"bathroom\",\"not_bathroom\"]\n",
    "layout = \"{!s:^10} {!s:^10} {!s:^10}\"\n",
    "print(layout.format(\"\",\"bathroom\",\"not_bathroom\"))\n",
    "list_layout = \"{!s:<10} {:^10.4f} {:^10.4f}\"\n",
    "# nums = [12.0, 13.234234,12.2323232323,12.2323232323,12.2323232323,12.2323232323,99.123123123123,99.123123123123,99.123123123123,99.123123123123]\n",
    "# print(list_layout.format(\"air_cond\",*nums))\n",
    "for i in range(len(copy)):\n",
    "    to_print = [names[i]] + copy[i]\n",
    "    print(list_layout.format(*to_print))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parent_dir = 'Sound-Data/renameThese'\n",
    "dirs = [\"Ambient_1_16\",\"Ambient_1_17\",\"Ambient_1_18\"]\n",
    "features, labels = parse_audio_files(parent_dir, dirs)\n",
    "# print(features)\n",
    "# print(features.shape)\n",
    "# print(labels)\n",
    "# print(labels.shape)\n",
    "# labels = one_hot_encode(labels)\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./checkpoints/NN-model.ckpt\")\n",
    "    print(\"Model restored\")\n",
    "    new_pred = sess.run(tf.argmax(y_,1),feed_dict={X: features})\n",
    "#     new_true = sess.run(tf.argmax(labels,1))\n",
    "    saver.save(sess, \"./checkpoints/\"+\"NN-model.ckpt\")\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# newtypes = {10: \"driving\",11:\"keyboard\",12:\"mouseclick\"}\n",
    "data_types = {0: \"bathroom\", 1: \"not_bathroom\"}\n",
    "# for i,j in (labels,new_pred):\n",
    "#     print(str(newtype[i]) + \"->\" + str(names[i]))\n",
    "# for i in labels:\n",
    "#     print(newtypes[i],end=\" \\t\")\n",
    "# print()\n",
    "# for i in new_pred:\n",
    "#     print(names[i], end=\"\\t\")\n",
    "\n",
    "\n",
    "# count = 0\n",
    "# sum = 0\n",
    "# for i in new_pred:\n",
    "#     print(names[i])\n",
    "#     sum += i\n",
    "#     if i == 2:\n",
    "#         count += 1\n",
    "# print(new_pred.shape[0])\n",
    "count = 0\n",
    "predSum = 0\n",
    "timer = 0\n",
    "bathCount = 0\n",
    "for i in new_pred:\n",
    "    if (data_types[labels[timer]] == \"bathroom\"):\n",
    "        count += 1\n",
    "    if (str(data_types[labels[timer]]) == str(names[i])):\n",
    "        predSum += 1\n",
    "        if (data_types[labels[timer]] == \"bathroom\"):\n",
    "            bathCount += 1\n",
    "#     else:\n",
    "#         print(str(data_types[labels[timer]]) + \": \" + str(names[i]))\n",
    "    \n",
    "    timer += 1\n",
    "print(predSum / new_pred.shape[0])\n",
    "print(count)\n",
    "print(bathCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## distinguish home events\n",
    "### -watching tv\n",
    "### -using toilet -> Starting point, get samples of this first and washing hands sounds, try to record in pocket as well as outside\n",
    "### -housework (ie vacuum, chores)\n",
    "### -talking\n",
    "## Problems\n",
    "### -phone in pocket\n",
    "### -sampling size/length\n",
    "\n",
    "## remove not needed sounds -> \n",
    "#     keep air conditioning, children playing, street music\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parent_dir = 'New-Data'\n",
    "dirs = [\"fold2\", \"fold3\",\"fold4\"]\n",
    "features, labels = parse_audio_files(parent_dir, dirs)\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./checkpoints/NN-model.ckpt\")\n",
    "    print(\"Model restored\")\n",
    "    new_pred = sess.run(tf.argmax(y_,1),feed_dict={X: features})\n",
    "#     new_true = sess.run(tf.argmax(labels,1))\n",
    "    saver.save(sess, \"./checkpoints/\"+\"NN-model.ckpt\")\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_types = {3: \"toilet\", 4:\"watching_tv\", 5: \"cafe/office\"}\n",
    "\n",
    "count = 0\n",
    "sum = 0\n",
    "timer = 0\n",
    "for i in new_pred:\n",
    "    print(str(data_types[labels[timer]]) + \": \" + str(names[i]))\n",
    "    sum += i\n",
    "    if i == 2:\n",
    "        count += 1\n",
    "    timer += 1\n",
    "print(count*2 / sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## get recording of open/real space sounds, like cafe, office, etc\n",
    "# analyze conituous ambient sound, if the sound changes, that would be the moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
